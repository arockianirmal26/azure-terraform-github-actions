{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<mark>Business-Gold â†’ Aggregated, curated data (ready for analytics/reporting)</mark>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "# Access parameter directly from Refined-Silver notebook / (Toggle parameter cell\n",
        "\n",
        "bronze_output = \"\"\n",
        "silver_data = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import json\n",
        "\n",
        "# Parse the JSON string\n",
        "bronze_data = json.loads(bronze_params)\n",
        "\n",
        "# Access individual variables\n",
        "start_date = bronze_data.get(\"start_date\", \"\")\n",
        "silver_adls = bronze_data.get(\"silver_adls\", \"\")\n",
        "gold_adls = bronze_data.get(\"gold_adls\", \"\")\n",
        "\n",
        "print(f\"Start Date: {start_date}\")\n",
        "print(f\"Silver ADLS: {silver_adls}\")\n",
        "print(f\"Gold ADLS: {gold_adls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "Synapsedemo",
              "statement_id": 3,
              "statement_ids": [
                3
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2025-09-13T10:28:47.9795328Z",
              "session_start_time": null,
              "execution_start_time": "2025-09-13T10:28:47.9812993Z",
              "execution_finish_time": "2025-09-13T10:28:48.252224Z",
              "parent_msg_id": "7a1de911-1243-4071-9c4f-49313f8fd51e"
            },
            "text/plain": "StatementMeta(Synapsedemo, 4, 3, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# For manually testing the notebook / remove before running in Data Factory Pipeline \n",
        "#import json\n",
        "#from datetime import date, timedelta\n",
        "\n",
        "#start_date = date.today() - timedelta(1)\n",
        "\n",
        "#silver_adls = \"abfss://refined-silver@synapsetest1298.dfs.core.windows.net/\"\n",
        "#gold_adls = \"abfss://business-gold@synapsetest1298.dfs.core.windows.net/\"\n",
        "\n",
        "#silver_data = f\"{silver_adls}earthquake_events_silver/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "Synapsedemo",
              "statement_id": 4,
              "statement_ids": [
                4
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2025-09-13T10:28:51.5815635Z",
              "session_start_time": null,
              "execution_start_time": "2025-09-13T10:28:51.5833366Z",
              "execution_finish_time": "2025-09-13T10:28:57.0811532Z",
              "parent_msg_id": "65f93f8c-5498-4e13-a471-09762a69f8eb"
            },
            "text/plain": "StatementMeta(Synapsedemo, 4, 4, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# Import Libraries\n",
        "\n",
        "from pyspark.sql.functions import when, col, udf\n",
        "from pyspark.sql.types import StringType\n",
        "from datetime import date, timedelta\n",
        "# Ensure the below library is installed on your cluster\n",
        "import reverse_geocoder as rg\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "Synapsedemo",
              "statement_id": 5,
              "statement_ids": [
                5
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2025-09-13T10:29:01.6467625Z",
              "session_start_time": null,
              "execution_start_time": "2025-09-13T10:29:01.6485342Z",
              "execution_finish_time": "2025-09-13T10:29:20.7209015Z",
              "parent_msg_id": "ddccff3b-152c-431d-9413-bb278d51bffc"
            },
            "text/plain": "StatementMeta(Synapsedemo, 4, 5, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# Get the data from the silver layer\n",
        "\n",
        "df = spark.read.parquet(silver_data).filter(col('time') > start_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "Synapsedemo",
              "statement_id": 6,
              "statement_ids": [
                6
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2025-09-13T10:29:45.7194508Z",
              "session_start_time": null,
              "execution_start_time": "2025-09-13T10:29:45.7227126Z",
              "execution_finish_time": "2025-09-13T10:29:45.9913963Z",
              "parent_msg_id": "3ecef90b-37cd-44c4-8078-052dce991ad2"
            },
            "text/plain": "StatementMeta(Synapsedemo, 4, 6, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "def get_country_code(lat, lon):\n",
        "    \"\"\"\n",
        "    Retrieve the country code for a given latitude and longitude.\n",
        "\n",
        "    Parameters:\n",
        "    lat (float or str): Latitude of the location.\n",
        "    lon (float or str): Longitude of the location.\n",
        "\n",
        "    Returns:\n",
        "    str: Country code of the location, retrieved using the reverse geocoding API.\n",
        "\n",
        "    Example:\n",
        "    >>> get_country_details(48.8588443, 2.2943506)\n",
        "    'FR'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        coordinates = (float(lat), float(lon))\n",
        "        result = rg.search(coordinates)[0].get('cc')\n",
        "        print(f\"Processed coordinates: {coordinates} -> {result}\")\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing coordinates: {lat}, {lon} -> {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "Synapsedemo",
              "statement_id": 7,
              "statement_ids": [
                7
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2025-09-13T10:29:50.4197628Z",
              "session_start_time": null,
              "execution_start_time": "2025-09-13T10:29:50.4219814Z",
              "execution_finish_time": "2025-09-13T10:29:50.6927785Z",
              "parent_msg_id": "fed6cf28-12e3-497b-b345-f9601ce0da75"
            },
            "text/plain": "StatementMeta(Synapsedemo, 4, 7, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# registering the udfs so they can be used on spark dataframes\n",
        "get_country_code_udf = udf(get_country_code, StringType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "Synapsedemo",
              "statement_id": 8,
              "statement_ids": [
                8
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2025-09-13T10:30:00.1548721Z",
              "session_start_time": null,
              "execution_start_time": "2025-09-13T10:30:00.1565462Z",
              "execution_finish_time": "2025-09-13T10:30:00.4293358Z",
              "parent_msg_id": "c817fbfc-ac16-4ce0-9d4a-8c62d92c570f"
            },
            "text/plain": "StatementMeta(Synapsedemo, 4, 8, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# adding country_code and city attributes\n",
        "df_with_location = \\\n",
        "                df.\\\n",
        "                    withColumn(\"country_code\", get_country_code_udf(col(\"latitude\"), col(\"longitude\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "Synapsedemo",
              "statement_id": 9,
              "statement_ids": [
                9
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2025-09-13T10:30:03.5893115Z",
              "session_start_time": null,
              "execution_start_time": "2025-09-13T10:30:03.5911841Z",
              "execution_finish_time": "2025-09-13T10:30:03.8490016Z",
              "parent_msg_id": "3c32095e-069c-48e7-9b5f-08ca35c9353d"
            },
            "text/plain": "StatementMeta(Synapsedemo, 4, 9, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n |-- id: string (nullable = true)\n |-- longitude: double (nullable = true)\n |-- latitude: double (nullable = true)\n |-- elevation: double (nullable = true)\n |-- title: string (nullable = true)\n |-- place_description: string (nullable = true)\n |-- sig: long (nullable = true)\n |-- mag: double (nullable = true)\n |-- magType: string (nullable = true)\n |-- time: timestamp (nullable = true)\n |-- updated: timestamp (nullable = true)\n\nNone\nroot\n |-- id: string (nullable = true)\n |-- longitude: double (nullable = true)\n |-- latitude: double (nullable = true)\n |-- elevation: double (nullable = true)\n |-- title: string (nullable = true)\n |-- place_description: string (nullable = true)\n |-- sig: long (nullable = true)\n |-- mag: double (nullable = true)\n |-- magType: string (nullable = true)\n |-- time: timestamp (nullable = true)\n |-- updated: timestamp (nullable = true)\n |-- country_code: string (nullable = true)\n\nNone\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "# Printing schemas\n",
        "\n",
        "print(df.printSchema())\n",
        "print(df_with_location.printSchema())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "Synapsedemo",
              "statement_id": 10,
              "statement_ids": [
                10
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2025-09-13T10:30:17.0495149Z",
              "session_start_time": null,
              "execution_start_time": "2025-09-13T10:30:17.0513267Z",
              "execution_finish_time": "2025-09-13T10:30:17.31243Z",
              "parent_msg_id": "0751327f-7590-4c34-a798-941f5b51d283"
            },
            "text/plain": "StatementMeta(Synapsedemo, 4, 10, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n |-- id: string (nullable = true)\n |-- longitude: double (nullable = true)\n |-- latitude: double (nullable = true)\n |-- elevation: double (nullable = true)\n |-- title: string (nullable = true)\n |-- place_description: string (nullable = true)\n |-- sig: long (nullable = true)\n |-- mag: double (nullable = true)\n |-- magType: string (nullable = true)\n |-- time: timestamp (nullable = true)\n |-- updated: timestamp (nullable = true)\n |-- country_code: string (nullable = true)\n |-- sig_class: string (nullable = false)\n\nNone\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "# adding significance classification\n",
        "df_with_location_sig_class = \\\n",
        "                            df_with_location.\\\n",
        "                                withColumn('sig_class', \n",
        "                                            when(col(\"sig\") < 100, \"Low\").\\\n",
        "                                            when((col(\"sig\") >= 100) & (col(\"sig\") < 500), \"Moderate\").\\\n",
        "                                            otherwise(\"High\")\n",
        "                                            )\n",
        "\n",
        "print(df_with_location_sig_class.printSchema())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "Synapsedemo",
              "statement_id": 11,
              "statement_ids": [
                11
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2025-09-13T10:30:35.6996398Z",
              "session_start_time": null,
              "execution_start_time": "2025-09-13T10:30:35.7014182Z",
              "execution_finish_time": "2025-09-13T10:30:35.9662054Z",
              "parent_msg_id": "cbbb2a98-f330-4d72-adce-4040ebe0cfea"
            },
            "text/plain": "StatementMeta(Synapsedemo, 4, 11, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# Save the transformed DataFrame to the gold container\n",
        "gold_output_path = f\"{gold_adls}earthquake_events_gold/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "Synapsedemo",
              "statement_id": 12,
              "statement_ids": [
                12
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2025-09-13T10:30:38.5073015Z",
              "session_start_time": null,
              "execution_start_time": "2025-09-13T10:30:38.5090996Z",
              "execution_finish_time": "2025-09-13T10:31:14.1534429Z",
              "parent_msg_id": "1dd6b46e-0d85-4b59-8703-46b964a67196"
            },
            "text/plain": "StatementMeta(Synapsedemo, 4, 12, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# append DataFrame to gold container in Parquet format / (overwrite to test)\n",
        "df_with_location_sig_class.write.mode('overwrite').parquet(gold_output_path)"
      ]
    }
  ]
}